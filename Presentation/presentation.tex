\documentclass[aspectratio=169]{beamer}
\usetheme[progressbar=frametitle, numbering=fraction]{metropolis}
 % Modern, minimal theme
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.95\paperwidth,ht=2.5ex,dp=1ex,leftskip=1em]{author in head/foot}%
    \usebeamerfont{author in head/foot}\insertshortauthor\hspace{1em}-- \insertshortinstitute
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.3\paperwidth,ht=2.5ex,dp=1ex,rightskip=1em]{date in head/foot}%
    \usebeamerfont{date in head/foot}\insertframenumber{} / \inserttotalframenumber
  \end{beamercolorbox}}%

}

\usepackage{graphicx}   % Images
\usepackage{minted}
\usepackage{booktabs}   % Tables
\usepackage{amsmath}    % Math support
\usepackage{caption}
\captionsetup[figure]{labelfont={scriptsize}, textfont={scriptsize}}
% Code blocks (use -shell-escape to compile)
\usepackage{tikz}       % Diagrams (optional)

% Metadata
\title{I/O Performance trade-offs among RNTuple’s persistent layouts for DUNE Data Products}
\subtitle{}
\author{S M Shovan, \textit{FCSI Summer Intern'25}}

\institute{Fermi National Accelerator Laboratory}
\date{\today}

\begin{document}

% Title Slide
\maketitle


% Outline
\begin{frame}{Outline}
\tableofcontents
\end{frame}

\section{Introduction}

\begin{frame}{Introduction}
  \begin{itemize}
    \item The Deep Underground Neutrino Experiment (DUNE) is projected to record roughly 30~PB of liquid‑argon TPC data per year\,[1]—far beyond the scale of previous neutrino experiments.
    \item DUNE’s \textbf{Phlex} test‑stand at Fermilab provides realistic hit/wire samples to prototype read‑out and offline storage.
    \item ROOT’s new \texttt{RNTuple} backend is a candidate for the long‑term DUNE data model, promising faster compression, cluster‑aware reads, and thread‑safe writes.
    \item This study benchmarks alternative RNTuple \emph{persistent layouts} (AOS/SOA, vertical splits, granularity levels) using Phlex‑generated Hit and Wire data products.
    \item Focus data products: \texttt{recob::Hit} (charge deposits) and \texttt{recob::Wire} (ROI‑compressed waveforms).
  \end{itemize}
\end{frame}

\begin{frame}{Motivation}
  \begin{itemize}
    \item A single DUNE far‑detector module streams about 1.2\,TB/s of raw data before compression\,[2]; naive storage could potentially overwhelm the archival budget.
    \item Efficient layout choice can cut file size and accelerate cluster reads needed for GPU/CPU reconstruction farms.
  \end{itemize}
\end{frame}

\begin{frame}{Problem Statement}
  \begin{itemize}
    \item Which RNTuple persistent layout minimises \emph{both} write time and on‑disk footprint for DUNE Hit/Wire hierarchies?
    \item How does vertical splitting (all‑DP, per‑DP, per‑group) interact with horizontal granularities (event, spill, element) under Phlex workloads?
  \end{itemize}
\end{frame}

\begin{frame}{Objectives}
  \begin{itemize}
    \item Benchmark seven layout variants on a 1\,M‑event Phlex dataset (\texttt{recob::Hit}, \texttt{recob::Wire} with ROIs).
    \item Measure: write throughput, cold/warm read latency, compressed file size, and multi‑thread scaling (1--64 threads).
    \item Quantify trade‑offs of ROI flattening, vertical split depth, and SOA vs. AOS in the context of DUNE’s access patterns.
  \end{itemize}
\end{frame}

% -------- Section: Persistent Layouts --------
\section{Persistent Layouts}
\begin{frame}{Data Layouts: AOS vs. SOA}
  \begin{columns}
    \column{0.5\textwidth}
    \textbf{Array of Structures (AOS)} \\
    \small Stores complete objects in an array. 
    \vspace{0.5em}
    \fbox{\parbox{0.9\textwidth}{\small
    \texttt{struct Hit \{ }\\
    \texttt{    long long EventID; }\\
    \texttt{    unsigned int fChannel; }\\
    \texttt{    float fPeakTime; }\\
    \texttt{\}; }\\
    \texttt{// Array: [Hit1, Hit2, ...]}
    }}
    \vspace{0.5em}
    \textbf{Example}: Hit, Wire (per-item entries).

    \column{0.5\textwidth}
    \textbf{Structure of Arrays (SOA)} \\
    \small Separate arrays per field.
    \vspace{0.5em}
    \fbox{\parbox{0.9\textwidth}{\small
    \texttt{struct Hits \{ }\\
    \texttt{    vector<unsigned int> fChannel; }\\
    \texttt{    vector<float> fPeakTime; }\\
    \texttt{\}; }\\
    \texttt{// Columns: fChannel[ ], fPeakTime[ ], ...}
    }}
    \vspace{0.5em}
    \textbf{Example}: Hits, Wires (per-event vectors).
  \end{columns}
  \vspace{1em}
\end{frame}



\begin{frame}{Layout Strategies}

  \begin{columns}
    % Left column (30%)
    \column{0.20\textwidth}
    \centering
    \includegraphics<1->[width=\textwidth]{Figures/AOSLayout.pdf}
    \only<1->{\captionof{figure}{\scriptsize AOS Layout}}

    % Right column (70%)
    \column{0.7\textwidth}
    % Top row (appears on slide 2)
    \begin{columns}
      \column{0.33\textwidth}
      \centering
      \includegraphics<2->[height=0.15\textheight]{Figures/Vertical1.pdf}
      \only<2->{\captionof{figure}{\scriptsize 1 RNTuple for all data products}}

      \column{0.33\textwidth}
      \centering
      \includegraphics<2->[height=0.15\textheight]{Figures/Vertical2.pdf}
      \only<2->{\captionof{figure}{\scriptsize 1 RNTuple per data product}}

      \column{0.33\textwidth}
      \centering
      \includegraphics<2->[height=0.15\textheight]{Figures/Vertical3.pdf}
      \only<2->{\captionof{figure}{\scriptsize 1 RNTuple per group }}
    \end{columns}

    \vspace{0.5em}

    % Bottom row (appears on slide 3)
    \begin{columns}
      \column{0.25\textwidth}
      \centering
      \includegraphics<3->[height=0.13\textheight]{Figures/Hori1.pdf}
      \only<3->{\captionof{figure}{\scriptsize 1 fill/row per event}}

      \column{0.25\textwidth}
      \centering
      \includegraphics<3->[height=0.13\textheight]{Figures/Hori2.pdf}
      \only<3->{\captionof{figure}{\scriptsize 1 fill/row per spill}}

      \column{0.25\textwidth}
      \centering
      \includegraphics<3->[height=0.13\textheight]{Figures/Hori3.pdf}
      \only<3->{\captionof{figure}{\scriptsize 1 fill/row per top object}}

      \column{0.25\textwidth}
      \centering
      \includegraphics<3->[height=0.13\textheight]{Figures/Hori4.pdf}
      \only<3->{\captionof{figure}{\scriptsize 1 fill/row per element}}
    \end{columns}
  \end{columns}
\end{frame}

% Layout Strategies: AOS vs SOA
\begin{frame}{Layout Strategies: AOS vs SOA}
  \begin{columns}
    \column{0.25\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Figures/AOSLayout.pdf}
    \captionof{figure}{\scriptsize AOS Layout}

    \column{0.25\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Figures/SOALayout.pdf}
    \captionof{figure}{\scriptsize SOA Layout}
  \end{columns}
\end{frame}

% -------- Granularity × Vertical‑split matrix --------
\begin{frame}{Granularity vs.\ Vertical Split Matrix}
\small\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{\shortstack{Horizontal\\Granularity}} &
\textbf{\shortstack{1 NTuple\\(all DP)}} &
\textbf{\shortstack{1 NTuple\\/ DP}} &
\textbf{\shortstack{1 NTuple\\/ group}}\\
\midrule
Event‑wise      & \texttt{event\_allDP()}     & \texttt{event\_perDP()}     & \texttt{event\_perGroup()}\\
Spill‑wise      & \texttt{spill\_allDP()}     & \texttt{spill\_perDP()}     & \texttt{spill\_perGroup()}\\
Top‑object‑wise & --                                   & \texttt{topObject\_perDP()} & \texttt{topObject\_perGroup()}\\
Element‑wise    & --                                   & \texttt{element\_perDP()}   & \texttt{element\_perGroup()}\\
\bottomrule
\end{tabular}
\\[0.4em]
{\small DP = Data Product}
\end{frame}

\begin{frame}{Memory/Data Considerations}
  % Add your content here
\end{frame}

\begin{frame}{Memory/Data Considerations}
% Add your content here
\end{frame}

\section{Parallel Optimizations}
\begin{frame}{Write Optimization: Multi-Threaded Chunking}
  \begin{columns}
    \column{0.5\textwidth}
    \textbf{Parallel Chunking}
    \small Divide events into thread-specific ranges for concurrent filling.
    \vspace{0.5em}
    \fbox{\parbox{0.9\textwidth}{\scriptsize
    \texttt{std::vector<unsigned int> seeds = generateSeeds(nThreads); }\\
    \texttt{for (int th = 0; th < nThreads; ++th) \{ }\\
    \texttt{    int first = th * chunkSize; }\\
    \texttt{    int last = std::min(first + chunkSize, totalEvents); }\\
    \texttt{    futures.emplace\_back(std::async( }\\
    \texttt{        std::launch::async, thinWorkFunc, first, last, seeds[th], th ));\}}}} 
    \vspace{0.5em}
    \textbf{Example}: \texttt{executeInParallel} writers.

    \column{0.5\textwidth}
    \textbf{Synchronized Filling}
    \small Use mutex to safely flush clusters after filling.
    \vspace{0.5em}
    \fbox{\parbox{0.9\textwidth}{\scriptsize
    \texttt{\{ std::lock\_guard<std::mutex> lock(mutex); \} }\\
    \texttt{hitContext.FlushCluster(); }
    }}
    \vspace{0.5em}
    \textbf{Project Use}: Scales writes with cores for large datasets.
  \end{columns}
\end{frame}

\begin{frame}{Read Optimization: Cluster-Aware Splitting}
  \begin{columns}
    \column{0.5\textwidth}
    \textbf{Cluster Splitting}
    \small Split read ranges by cluster boundaries to avoid duplicates.
    \vspace{0.5em}
    \fbox{\parbox{0.9\textwidth}{\scriptsize
    \texttt{auto clusters = split\_range\_by\_clusters(*reader, nChunks); }\\
    \texttt{for (auto\& chunk : clusters) \{ }\\
    \texttt{    futures.push\_back(std::async( }\\
    \texttt{        \&processChunk, chunk.first, chunk.second }\\
    \texttt{    )); }\\
    \texttt{\} }
    }}
    \vspace{0.5em}

    \column{0.5\textwidth}
    \textbf{Benefits}
    \small Prevents redundant reads, optimizes multi-threaded access.
    \vspace{0.5em}
    \fbox{\parbox{0.9\textwidth}{\scriptsize
    \texttt{std::vector<std::pair<size\_t, size\_t>> }\\
    \texttt{split\_range\_by\_clusters(ROOT::RNTupleReader\& reader, int nChunks) }
    }}
    \vspace{0.5em}
    \textbf{Project Use}: Enhances read efficiency.
  \end{columns}
\end{frame}


% -------- Section: Challenges --------
\section{Challenges}
\begin{frame}{Parallel Write Challenge: File Corruption Solution}
  \begin{columns}
    \column{0.4\textwidth}
    \textbf{Problem: Concurrent Flushes}
    \small Unsynchronized cluster flushes cause file corruption in multi-threaded writes.
    \vspace{0.5em}
    \textbf{Example Issue}: Threads overwriting shared file regions.

    \column{0.6\textwidth}
    \textbf{Solution: Mutex Synchronization}
    \small Lock during flushes to serialize access per cluster.
    \vspace{0.5em}
    \fbox{\parbox{0.9\textwidth}{\scriptsize
    \texttt{for (int idx = first; idx < last; ++idx) \{ }\\
    \texttt{  // Generate data for hits/wires }\\
    \texttt{  if (hitStatus.ShouldFlushCluster()) \{ }\\
    \texttt{    hitContext.FlushColumns(); }\\
    \texttt{    \{ std::lock\_guard<std::mutex> lock(mutex); \} }\\
    \texttt{    hitContext.FlushCluster(); }\\
    \texttt{  \} }\\
    \texttt{\} }
    }}
    \vspace{0.5em}
    \textbf{Project Use}: Ensures thread-safe parallel writes without corruption.
  \end{columns}
\end{frame}
\begin{frame}{ROI Flattening vs. Custom Dictionary}
  \begin{columns}
    \column{0.5\textwidth}
    \textbf{ROI Flattening (Non-Dictionary)}
    \small Flattens hierarchical ROI data into vectors for efficient storage without custom classes.
    \vspace{0.5em}
    \fbox{\parbox{0.9\textwidth}{\scriptsize
    \texttt{struct Wires \{ }\\
    \texttt{    vector<unsigned int> fSignalROI\_nROIs; }\\
    \texttt{    vector<size\_t> fSignalROI\_offsets; }\\
    \texttt{    vector<float> fSignalROI\_data; }\\
    \texttt{\}; }
    }}
    \vspace{0.5em}
    \textbf{Example}: Used in non-dictionary experiments for raw vector-based I/O.

    \column{0.5\textwidth}
    \textbf{Custom Dictionary (ROOT Classes)}
    \small Uses structured classes with ClassDef for ROOT's dictionary system, enabling object-oriented I/O.
    \vspace{0.5em}
    \fbox{\parbox{0.9\textwidth}{\scriptsize
    \texttt{struct RegionOfInterest \{ }\\
    \texttt{    size\_t offset; }\\
    \texttt{    vector<float> data; }\\
    \texttt{    ClassDef(RegionOfInterest, 3) }\\
    \texttt{\}; }
    }}
    \vspace{0.5em}
    \textbf{Example}: Used in dictionary experiments for type-safe, hierarchical data handling.
  \end{columns}
  \vspace{1em}
\end{frame}


% -------- Section: Results --------
\section{Results}

\begin{frame}{Evaluation Metrics}
\small
\begin{itemize}
  \item \textbf{Write Throughput:} Total events per second during RNTuple serialization.
  \item \textbf{Cold Read Time:} Latency for first access after file creation, reflecting raw I/O.
  \item \textbf{Warm Read Time:} Latency when data is cached, measuring memory locality effects.
  \item \textbf{Compressed File Size:} Total on-disk footprint post-write, accounting for RNTuple's column-wise compression.
  \item \textbf{Multi-thread Scaling:} Performance variation from 1 to 64 threads for write and read workloads.
\end{itemize}
\end{frame}


\begin{frame}{AOS vs SOA: Write Performance Comparison}
\centering
\includegraphics[width=0.9\linewidth]{../experiments/comparison_write_times.pdf}
\captionof{figure}{\small Write Performance Comparison: AOS vs SOA approaches across different data organization strategies. Red bars represent AOS (Array of Structures) performance, while blue bars show SOA (Structure of Arrays) performance.}
\end{frame}
\begin{frame}[c]{CPU Time Overheads}
  \small
  \begin{columns}[c,onlytextwidth]
    \column{0.55\textwidth}
    \footnotesize
    \begin{tabular}{lccc}
      \toprule
      Writer & A & B & C\\
      \midrule
      \texttt{event\_perGroup}   & \checkmark & \checkmark & \\
      \texttt{spill\_perGroup}   & \checkmark & \checkmark & \checkmark\\
      \texttt{element\_perData}  & \checkmark & \checkmark & \\
      \texttt{topObject\_perData}&   & \checkmark & \\
      \texttt{event\_perData}    &   & \checkmark & \\
      \texttt{spill\_perData}    &   & \checkmark & \checkmark\\
      \bottomrule
    \end{tabular}
    \column{0.45\textwidth}\\[0.3em]
    \begin{itemize}
      \item \textbf{A – ROI flattening:} dominant for *element* and *perGroup* writers.
      \item \textbf{B – Multiple NTuples:} extra \texttt{Fill}/Flush cycles \& mutex contention.
      \item \textbf{C – Spill re-partitioning:} additional work unique to *spill* writers.
    \end{itemize}
  \end{columns}
  \end{frame}

\begin{frame}{AOS vs SOA: Cold Read Performance Comparison}
\centering
\includegraphics[width=0.9\linewidth]{../experiments/comparison_cold_times.pdf}
\captionof{figure}{\small Cold Read Performance Comparison: Initial read times for AOS vs SOA implementations. Cold reads represent the first access to data after file creation, measuring baseline I/O performance.}
\end{frame}

\begin{frame}{AOS vs SOA: Warm Read Performance Comparison}
\centering
\includegraphics[width=0.9\linewidth]{../experiments/comparison_warm_times.pdf}
\captionof{figure}{\small Warm Read Performance Comparison: Subsequent read times for AOS vs SOA implementations. Warm reads benefit from cached data, showing optimized access patterns and memory locality effects.}
\end{frame}

\begin{frame}{AOS vs SOA: File Size Comparison}
\centering
\includegraphics[width=0.9\linewidth]{../experiments/comparison_file_sizes.pdf}
\captionof{figure}{\small File Size Comparison: Storage efficiency of AOS vs SOA approaches. File sizes impact storage costs, network transfer times, and overall data management overhead in large-scale HEP experiments.}
\end{frame}

% -------- Section: Trade-offs --------

% -------- Concise insight slides automatically inserted --------
\begin{frame}[c]{File Size Insights}
\small
\begin{columns}[c,onlytextwidth]
  \column{0.50\textwidth}
  \begin{tabular}{@{}ll@{}}
  \toprule
  Writer variant & Size (\% of most)\\
  \midrule
  \texttt{aos\_element\_perData.root} & 47\%\\
  \texttt{soa\_element\_perData.root} & 100\%\\
  \texttt{aos\_element\_perGroup.root} & 42\%\\
  \texttt{soa\_element\_perGroup.root} & 39\%\\
  \texttt{aos\_event\_* / aos\_spill\_*} & $\sim$103\%\\
  \texttt{soa\_event\_* / soa\_spill\_*} & 100\%\\
  \bottomrule
  \end{tabular}

  \column{0.45\textwidth}
  \textbf{Key Take-aways}\\[0.3em]
  \begin{itemize}
    \item Deep nesting \& high row counts double basket overhead (offset tables, headers, CRC).
    \item Flattened \texttt{perGroup} writers cut size roughly in half by removing ROI nesting.
  \end{itemize}
\end{columns}
\end{frame}


% -------- End of automatically inserted insight slides --------

\section{Trade-offs}
\begin{frame}{Trade-off Analysis}
% Add your content here
\end{frame}

\begin{frame}{Future Considerations}
% Add your content here
\end{frame}

% References Slide
\begin{frame}[allowframebreaks]{References}
\small
[1] DUNE Collaboration, “Deep Underground Neutrino Experiment Technical Design Report– VolumeII: DUNE Physics,” 2020, Sec.2.6.\par
[2] DUNE Collaboration, “Data Acquisition System for the DUNE Far Detector,” IEEE NSS/MIC Proc., 2023.\\
\end{frame}

% Final Slide
\begin{frame}[standout]
Thank you! \\
Questions?
\end{frame}

\end{document}
